name: Parallel Commit Backfill

on:
  workflow_dispatch:
    inputs:
      start_offset_days:
        description: "How many days ago to start (e.g. 30 → start from 30 days ago)"
        required: true
        default: 30
      backfill_days:
        description: "How many days to backfill from that start"
        required: true
        default: 30

jobs:
  backfill:
    runs-on: ubuntu-latest
    timeout-minutes: 4320        # per‐job timeout (max 6 h); bump up to 720 if needed
    strategy:
      fail-fast: false          # let all matrix slices run, even if one errors
      matrix:
        chunk: [0,1,2,3,4,5]     # 6 parallel slices;

    steps:
      - name: Checkout repo
        uses: actions/checkout@v4

      - name: Set up Java & Maven
        run: |
          sudo apt-get update
          sudo apt-get install -y maven openjdk-17-jdk

      - name: Set up Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '18'

      - name: Compute date window for chunk ${{ matrix.chunk }}
        id: dates
        run: |
          DAYS=${{ github.event.inputs.backfill_days }}
          START_OFFSET=${{ github.event.inputs.start_offset_days }}
          SLICES=6
          CHUNK_SIZE=$(( (DAYS + SLICES - 1) / SLICES ))

          NOW=$(date -u +"%Y-%m-%dT%H:%M:%SZ")
          # This slice ends at NOW - START_OFFSET - (chunk * CHUNK_SIZE)
          OFFSET_DAYS=$(( START_OFFSET + matrix.chunk * CHUNK_SIZE ))
          CHUNK_END=$(date -u -d "$NOW - $OFFSET_DAYS days" +"%Y-%m-%dT%H:%M:%SZ")
          CHUNK_START=$(date -u -d "$CHUNK_END - $CHUNK_SIZE days" +"%Y-%m-%dT%H:%M:%SZ")

          echo "::set-output name=start::$CHUNK_START"
          echo "::set-output name=end::$CHUNK_END"

      - name: Run backfill for chunk ${{ matrix.chunk }}
        continue-on-error: true    # produce partial output even if it fails
        run: |
          CHUNK_DIR="data/chunk-${{ matrix.chunk }}"
          mkdir -p "$CHUNK_DIR"
          scripts/.pinot_backfill_commit_compare.sh \
            --start "${{ steps.dates.outputs.start }}" \
            --end   "${{ steps.dates.outputs.end }}" \
            --outdir "$CHUNK_DIR"
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}

      - name: Upload chunk-artifact
        uses: actions/upload-artifact@v4
        with:
          name: chunk-${{ matrix.chunk }}
          path: data/chunk-${{ matrix.chunk }}

  merge:
    needs: backfill
    if: ${{ always() }}        # run even if backfill failed/timed-out
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repo
        uses: actions/checkout@v4

      - name: Download all chunk artifacts
        uses: actions/download-artifact@v4
        with:
          path: artifacts/

      - name: Combine all reports
        run: |
          mkdir -p data/japicmp data/output
          # collect every japicmp JSON
          find artifacts/ -type f -path "*/japicmp/*.json" \
            -exec cp {} data/japicmp/ \;
          # collect every parsed JSON
          find artifacts/ -type f -path "*/output/*.json" \
            -exec cp {} data/output/ \;

      - name: Commit & push combined reports
        run: |
          if [[ -n "$(git status --porcelain)" ]]; then
            git config user.name "github-actions[bot]"
            git config user.email "github-actions[bot]@users.noreply.github.com"
            git add data/japicmp data/output
            git commit -m "chore: backfill commit reports (last ${{ github.event.inputs.backfill_days }}d from ${{ github.event.inputs.start_offset_days }}d ago)"
            git push
          else
            echo "No new reports to commit"
          fi
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

      - name: Trigger Pages deploy
        run: gh workflow run deploy-pages.yml --ref main
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}